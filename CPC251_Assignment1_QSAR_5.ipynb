{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25ce659a",
   "metadata": {},
   "source": [
    "\n",
    "## Anjumanara Athina 155142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de5db89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8988107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('assignment1_dataset.csv', sep=',')# write data into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fa5a98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           f1        f2        f3        f4        f5   response\n",
      "0   -0.764216 -1.016209  0.149410 -0.050119 -0.578127   6.242514\n",
      "1    0.763880 -1.159509 -0.721492 -0.654067 -0.431670  -8.118241\n",
      "2    0.519329 -0.664621 -1.694904  1.339779  0.182764  66.722455\n",
      "3   -0.177388  0.515623  0.135144 -0.647634 -0.405631 -27.716793\n",
      "4    0.104022  0.749665 -0.939338 -0.090725 -0.639963   8.192075\n",
      "..        ...       ...       ...       ...       ...        ...\n",
      "995 -0.310133  0.529274 -1.439255  0.724974  0.430063  35.181828\n",
      "996 -0.731895 -0.223302 -1.228191 -2.034934  0.509077 -70.134876\n",
      "997  0.343181  0.431241 -0.054715  0.945423 -2.474684  42.925478\n",
      "998  0.391021  0.494147  0.106403 -0.652278 -0.200139 -13.287862\n",
      "999 -0.376168 -0.054266 -0.880176 -0.334246 -0.043447  -6.829767\n",
      "\n",
      "[1000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df) #check the values in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da746a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['f1','f2','f3','f4','f5']]#splitting response and \n",
    "y = df['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "101ca3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X,y, test_size=0.2)#to split the dataframe to 8:2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d80729",
   "metadata": {},
   "source": [
    "# Training_model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7944bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(X,y,alpha,max_epoch):\n",
    "    x1 = X_train['f1'].values#seperating each column to be calculated at respective weights\n",
    "    x2 = X_train['f2'].values\n",
    "    x3 = X_train['f3'].values\n",
    "    x4 = X_train['f4'].values\n",
    "    x5 = X_train['f5'].values\n",
    "    x= X_train.values \n",
    "    y = y_train.values #training set for responses\n",
    "    w1 = w2 = w3 = w4 = w5 = w0 = 0 \n",
    "    n = len(X) #determine size, in 8:2 case, it is 800\n",
    "    lostarr = [1]*(max_epoch)\n",
    "    \n",
    "    for i in range(max_epoch):\n",
    "        y_predict= w1*x1+w2*x2+w3*x3+w4*x4+w5*x5+w0 \n",
    "        w1 = w1 - alpha * -(2/n)*sum(x1*(y-y_predict)) # wᵢ = wᵢ - learning rate * derivate of wᵢ\n",
    "        w2 = w2 - alpha * -(2/n)*sum(x2*(y-y_predict))\n",
    "        w3 = w3 - alpha * -(2/n)*sum(x3*(y-y_predict))\n",
    "        w4 = w4 - alpha * -(2/n)*sum(x4*(y-y_predict))\n",
    "        w5 = w5 - alpha * -(2/n)*sum(x5*(y-y_predict))\n",
    "        w0 = w0 - alpha * -(2/n)*sum(y-y_predict) #intercept formula\n",
    "        hist_loss = (1/n) * sum((y-y_predict)**2) #loss formula\n",
    "        print(\"Estimated weight: w1=\",w1,\" ,w2=\",w2,\"w3=\",w3,\" ,w4=\",w4,\"w5=\",w5,\" ,w0=\",w0,\"loss: \",hist_loss,\" epoch:\",i,\"\\n\")\n",
    "        lostarr[i] = hist_loss\n",
    "        \n",
    "    return [w1,w2,w3,w4,w5,w0],lostarr #returning the estimated weights and training history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d01958",
   "metadata": {},
   "source": [
    "## Display training loss value for each epoch of the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd8da3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated weight: w1= 2.6340516363092426  ,w2= -0.10601937886971623 w3= 0.06737080671764528  ,w4= 8.162117084994529 w5= -0.3298404018399491  ,w0= 2.000821978012665 loss:  1778.8647206639191  epoch: 0 \n",
      "\n",
      "Estimated weight: w1= 4.676849513322379  ,w2= -0.17253626901358238 w3= 0.11171309188106379  ,w4= 14.51221978590873 w5= -0.5114860683491284  ,w0= 3.5820212203785813 loss:  1088.2096501036426  epoch: 1 \n",
      "\n",
      "Estimated weight: w1= 6.261871317215669  ,w2= -0.21162283312101504 w3= 0.13988126834793563  ,w4= 19.453140939146515 w5= -0.5936655626580672  ,w0= 4.831432928704183 loss:  669.9897216263597  epoch: 2 \n",
      "\n",
      "Estimated weight: w1= 7.492319084954861  ,w2= -0.23198902713040515 w3= 0.15682847245589526  ,w4= 23.298036472376694 w5= -0.6109330897470919  ,w0= 5.8185443996878154 loss:  416.5961538862743  epoch: 3 \n",
      "\n",
      "Estimated weight: w1= 8.448012672610268  ,w2= -0.2398697404062121 w3= 0.1661120095478884  ,w4= 26.290375520124538 w5= -0.5875299829620039  ,w0= 6.598319256553609 loss:  262.9790884546163  epoch: 4 \n",
      "\n",
      "Estimated weight: w1= 9.190708877741281  ,w2= -0.23968599376456573 w3= 0.17026816983607032  ,w4= 28.619468702619002 w5= -0.5402361028007442  ,w0= 7.214226521600851 loss:  169.7949511131194  epoch: 5 \n",
      "\n",
      "Estimated weight: w1= 9.768206618894276  ,w2= -0.23453632266447963 w3= 0.17108950455186503  ,w4= 30.432531714779316 w5= -0.4804681991820242  ,w0= 7.700639424412238 loss:  113.2350370032768  epoch: 6 \n",
      "\n",
      "Estimated weight: w1= 10.217515922532156  ,w2= -0.22656078550410289 w3= 0.16982939482478257  ,w4= 31.84405825458469 w5= -0.4158181515202661  ,w0= 8.084734747156508 loss:  78.88357371231132  epoch: 7 \n",
      "\n",
      "Estimated weight: w1= 10.56730479529991  ,w2= -0.21720964025167255 w3= 0.16735252510275112  ,w4= 32.94310318507734 w5= -0.3511756321836932  ,w0= 8.387996440695089 loss:  58.00710976323609  epoch: 8 \n",
      "\n",
      "Estimated weight: w1= 10.83978900466822  ,w2= -0.20744084433564208 w3= 0.1642451913677381  ,w4= 33.798942462158806 w5= -0.2895433056623409  ,w0= 8.627405760695659 loss:  45.3116274760092  epoch: 9 \n",
      "\n",
      "Estimated weight: w1= 11.052191994381303  ,w2= -0.19786455482686416 w3= 0.16089585485139712  ,w4= 34.465472078177086 w5= -0.23262526857638008  ,w0= 8.816383124253168 loss:  37.586114783288686  epoch: 10 \n",
      "\n",
      "Estimated weight: w1= 11.217873036023926  ,w2= -0.18884828166623158 w3= 0.15755370899689547  ,w4= 34.9846273272179 w5= -0.18124884750328185  ,w0= 8.965533362020235 loss:  32.88179934894682  epoch: 11 \n",
      "\n",
      "Estimated weight: w1= 11.34719927248583  ,w2= -0.18059292733874918 w3= 0.15437104514158986  ,w4= 35.38904086289627 w5= -0.13566442963337155  ,w0= 9.08323531294835 loss:  30.01523536682431  epoch: 12 \n",
      "\n",
      "Estimated weight: w1= 11.448220009175179  ,w2= -0.17318736602425477 w3= 0.15143371761024  ,w4= 35.704109237131235 w5= -0.09575643854060298  ,w0= 9.176108201690772 loss:  28.26728993889295  epoch: 13 \n",
      "\n",
      "Estimated weight: w1= 11.527188273165637  ,w2= -0.16664727119885256 w3= 0.14878289834149386  ,w4= 35.9495997322729 w5= -0.06118992522055922  ,w0= 9.249380494226058 loss:  27.20069397136379  epoch: 14 \n",
      "\n",
      "Estimated weight: w1= 11.588964379208868  ,w2= -0.1609424386138301 w3= 0.14643048178990392  ,w4= 36.140899887808914 w5= -0.031510798298510986  ,w0= 9.307181581267724 loss:  26.54939181072603  epoch: 15 \n",
      "\n",
      "Estimated weight: w1= 11.637328313921733  ,w2= -0.15601575416868557 w3= 0.14436988250075078  ,w4= 36.289989282554586 w5= -0.006212919663905123  ,w0= 9.352772402406819 loss:  26.15139449454985  epoch: 16 \n",
      "\n",
      "Estimated weight: w1= 11.675221635666151  ,w2= -0.1517961342354601 w3= 0.14258350759623273  ,w4= 36.40619539391712 w5= 0.015218270101420302  ,w0= 9.388727767139345 loss:  25.908007601261012  epoch: 17 \n",
      "\n",
      "Estimated weight: w1= 11.704934871851332  ,w2= -0.1482071517877447 w3= 0.1410478446634424  ,w4= 36.49678157687659 w5= 0.033278569329158215  ,w0= 9.417080469753357 loss:  25.7590585073347  epoch: 18 \n",
      "\n",
      "Estimated weight: w1= 11.728252757246395  ,w2= -0.14517260391742148 w3= 0.1397368522921646  ,w4= 36.56740450146965 w5= 0.04842919530891393  ,w0= 9.439435188901266 loss:  25.66783511290638  epoch: 19 \n",
      "\n",
      "Estimated weight: w1= 11.746566849568218  ,w2= -0.14261993612551496 w3= 0.13862415331560884  ,w4= 36.62247007164995 w5= 0.061088678030967125  ,w0= 9.457058494848987 loss:  25.61192296807377  epoch: 20 \n",
      "\n",
      "Estimated weight: w1= 11.760962891909196  ,w2= -0.1404821867667222 w3= 0.13768439281412423  ,w4= 36.6654103870196 w5= 0.071629868003365  ,w0= 9.47094996688744 loss:  25.57762713642031  epoch: 21 \n",
      "\n",
      "Estimated weight: w1= 11.772288618919161  ,w2= -0.13869892902457095 w3= 0.1368940215315427  ,w4= 36.69889928796716 w5= 0.08038022376299966  ,w0= 9.481898378060619 loss:  25.556574072599325  epoch: 22 \n",
      "\n",
      "Estimated weight: w1= 11.7812064120848  ,w2= -0.13721655107149938 w3= 0.1362316910862503  ,w4= 36.72502012268219 w5= 0.08762410000061083  ,w0= 9.490526077002443 loss:  25.543640116184307  epoch: 23 \n",
      "\n",
      "Estimated weight: w1= 11.788234211876533  ,w2= -0.13598811504007619 w3= 0.13567839318366323  ,w4= 36.74539634167884 w5= 0.09360615774899056  ,w0= 9.497324041937501 loss:  25.5356878163542  epoch: 24 \n",
      "\n",
      "Estimated weight: w1= 11.79377732382042  ,w2= -0.1349729626451769 w3= 0.13521743569600148  ,w4= 36.76129316796557 w5= 0.09853530492765906  ,w0= 9.502679563852901 loss:  25.530794510899653  epoch: 25 \n",
      "\n",
      "Estimated weight: w1= 11.798153159934413  ,w2= -0.13413618266676566 w3= 0.13483432005582044  ,w4= 36.77369675826187 w5= 0.10258877921815511  ,w0= 9.506898106016079 loss:  25.527781068427736  epoch: 26 \n",
      "\n",
      "Estimated weight: w1= 11.801610496521134  ,w2= -0.13344801773017623 w3= 0.13451656400477827  ,w4= 36.7833758457225 w5= 0.10591612837625153  ,w0= 9.510220562840134 loss:  25.525923789797304  epoch: 27 \n",
      "\n",
      "Estimated weight: w1= 11.804344473239148  ,w2= -0.13288326095266476 w3= 0.13425349919392873  ,w4= 36.79092974662526 w5= 0.10864294237640558  ,w0= 9.512836884717876 loss:  25.52477815238613  epoch: 28 \n",
      "\n",
      "Estimated weight: w1= 11.806508282924158  ,w2= -0.13242067412104924 w3= 0.1340360628532625  ,w4= 36.796825751821274 w5= 0.11087425952888283  ,w0= 9.514896832710281 loss:  25.524070898272935  epoch: 29 \n",
      "\n",
      "Estimated weight: w1= 11.80822228846812  ,w2= -0.13204244594484224 w3= 0.13385659556141655  ,w4= 36.801428253590586 w5= 0.11269761393219847  ,w0= 9.516518466682239 loss:  25.523633915860156  epoch: 30 \n",
      "\n",
      "Estimated weight: w1= 11.80958113803869  ,w2= -0.13173369998092996 w3= 0.13370865218768577  ,w4= 36.805021437271456 w5= 0.11418572091065812  ,w0= 9.517794843760417 loss:  25.523363697755958  epoch: 31 \n",
      "\n",
      "Estimated weight: w1= 11.81065932211047  ,w2= -0.13148205586333606 w3= 0.1335868297148142  ,w4= 36.80782696151806 w5= 0.11539881522591217  ,w0= 9.51879930382576 loss:  25.523196462215896  epoch: 32 \n",
      "\n",
      "Estimated weight: w1= 11.81151551674801  ,w2= -0.1312772436256767 w3= 0.133486613420579  ,w4= 36.81001773554492 w5= 0.11638666730101245  ,w0= 9.51958963959188 loss:  25.523092874603837  epoch: 33 \n",
      "\n",
      "Estimated weight: w1= 11.812195980813513  ,w2= -0.13111076854085715 w3= 0.13340424146322782  ,w4= 36.81172865622734 w5= 0.11719030793703844  ,w0= 9.520211386265185 loss:  25.523028657094223  epoch: 34 \n",
      "\n",
      "Estimated weight: w1= 11.81273721523565  ,w2= -0.1309756225631631 w3= 0.13333658703768086  ,w4= 36.81306497688906 w5= 0.11784349380214947  ,w0= 9.520700416356023 loss:  25.522988812757887  epoch: 35 \n",
      "\n",
      "Estimated weight: w1= 11.813168046279534  ,w2= -0.13086603781172534 w3= 0.13328105677162333  ,w4= 36.814108830926585 w5= 0.11837394557563864  ,w0= 9.521084986161707 loss:  25.522964069996465  epoch: 36 \n",
      "\n",
      "Estimated weight: w1= 11.813511258893893  ,w2= -0.13077727734560962 w3= 0.13323550378869  ,w4= 36.81492431768995 w5= 0.11880438890176115  ,w0= 9.52138734959696 loss:  25.522948692028887  epoch: 37 \n",
      "\n",
      "Estimated weight: w1= 11.813784878353825  ,w2= -0.1307054585829867 w3= 0.1331981537917514  ,w4= 36.815561467948385 w5= 0.119153425843801  ,w0= 9.521625030684612 loss:  25.522939126267975  epoch: 38 \n",
      "\n",
      "Estimated weight: w1= 11.814003176766558  ,w2= -0.13064740499383437 w3= 0.13316754255111504  ,w4= 36.81605933612855 w5= 0.11943626172703584  ,w0= 9.521811826779338 loss:  25.52293317087609  epoch: 39 \n",
      "\n",
      "Estimated weight: w1= 11.814177464170669  ,w2= -0.13060052206772693 w3= 0.13314246327753884  ,w4= 36.81644841189831 w5= 0.11966530938065897  ,w0= 9.521958599404453 loss:  25.52292946004062  epoch: 40 \n",
      "\n",
      "Estimated weight: w1= 11.814316710857822  ,w2= -0.13056269397191805 w3= 0.1331219224892415  ,w4= 36.81675250113862 w5= 0.11985068999696467  ,w0= 9.522073897586399 loss:  25.522927145825577  epoch: 41 \n",
      "\n",
      "Estimated weight: w1= 11.814428037345085  ,w2= -0.13053219773517763 w3= 0.13310510312622362  ,w4= 36.81699019322275 w5= 0.12000064721762553  ,w0= 9.522164449101705 loss:  25.522925701362723  epoch: 42 \n",
      "\n",
      "Estimated weight: w1= 11.814517100477834  ,w2= -0.13050763219782338 w3= 0.13309133381163488  ,w4= 36.817176005721066 w5= 0.12012188868236026  ,w0= 9.5222355475761 loss:  25.522924799003356  epoch: 43 \n",
      "\n",
      "Estimated weight: w1= 11.814588397946595  ,w2= -0.1304878593453096 w3= 0.13308006330088856  ,w4= 36.81732127755125 w5= 0.12021986715492881  ,w0= 9.522291357475533 loss:  25.522924234816646  epoch: 44 \n",
      "\n",
      "Estimated weight: w1= 11.814645508666384  ,w2= -0.13047195598499264 w3= 0.13307083929023533  ,w4= 36.8174348659346 w5= 0.12029901147577136  ,w0= 9.522335154372806 loss:  25.52292388176691  epoch: 45 \n",
      "\n",
      "Estimated weight: w1= 11.814691282692346  ,w2= -0.13045917403080806 w3= 0.13306329087530355  ,w4= 36.81752369031784 w5= 0.12036291596823624  ,w0= 9.522369514199431 loss:  25.522923660651983  epoch: 46 \n",
      "\n",
      "Estimated weight: w1= 11.814727991396035  ,w2= -0.1304489079287497 w3= 0.13305711405586151  ,w4= 36.81759315691171 w5= 0.120414495527821  ,w0= 9.522396462293512 loss:  25.522923522050235  epoch: 47 \n",
      "\n",
      "Estimated weight: w1= 11.814757446320487  ,w2= -0.13044066798904635 w3= 0.1330520597758992  ,w4= 36.81764749008707 w5= 0.12045611242942804  ,w0= 9.522417590767583 loss:  25.522923435096804  epoch: 48 \n",
      "\n",
      "Estimated weight: w1= 11.814781093327422  ,w2= -0.1304340585915247 w3= 0.13304792406871396  ,w4= 36.817689991093054 w5= 0.120489679873501  ,w0= 9.522434150916324 loss:  25.522923380499407  epoch: 49 \n",
      "\n",
      "Estimated weight: w1= 11.814800087236586  ,w2= -0.13042876040200443 w3= 0.1330445399460234  ,w4= 36.81772324005912 w5= 0.12051674643565527  ,w0= 9.522447125961317 loss:  25.522923346189344  epoch: 50 \n",
      "\n",
      "Estimated weight: w1= 11.814815351049347  ,w2= -0.13042451588300438 w3= 0.1330417707293461  ,w4= 36.81774925373189 w5= 0.12053856486494872  ,w0= 9.522457288307933 loss:  25.522923324610062  epoch: 51 \n",
      "\n",
      "Estimated weight: w1= 11.814827622979724  ,w2= -0.13042111750477903 w3= 0.13303950457215355  ,w4= 36.81776960866069 w5= 0.12055614807393276  ,w0= 9.522465244604556 loss:  25.52292331102654  epoch: 52 \n",
      "\n",
      "Estimated weight: w1= 11.814837493833696  ,w2= -0.13041839816579012 w3= 0.13303764996373327  ,w4= 36.81778553741067 w5= 0.12057031466174863  ,w0= 9.52247147119685 loss:  25.5229233024689  epoch: 53 \n",
      "\n",
      "Estimated weight: w1= 11.814845436741617  ,w2= -0.13041622341793324 w3= 0.13303613204138545  ,w4= 36.817798003717705 w5= 0.12058172589448782  ,w0= 9.52247634201971 loss:  25.5229232970732  epoch: 54 \n",
      "\n",
      "Estimated weight: w1= 11.814851830826889  ,w2= -0.13041448516367563 w3= 0.13303488956744852  ,w4= 36.81780776120057 w5= 0.12059091572147664  ,w0= 9.522480150536051 loss:  25.522923293668274  epoch: 55 \n",
      "\n",
      "Estimated weight: w1= 11.814856980062281  ,w2= -0.13041309655191327 w3= 0.1330338724525928  ,w4= 36.81781539923285 w5= 0.12059831512055466  ,w0= 9.522483126989913 loss:  25.522923291517877  epoch: 56 \n",
      "\n",
      "Estimated weight: w1= 11.814861128303797  ,w2= -0.13041198784874844 w3= 0.1330330397275751  ,w4= 36.817821378786626 w5= 0.12060427182993262  ,w0= 9.522485451972083 loss:  25.52292329015865  epoch: 57 \n",
      "\n",
      "Estimated weight: w1= 11.814864471285889  ,w2= -0.13041110310017304 w3= 0.13303235788288534  ,w4= 36.817826060443295 w5= 0.12060906633044759  ,w0= 9.522487267084252 loss:  25.52292328929885  epoch: 58 \n",
      "\n",
      "Estimated weight: w1= 11.81486716619915  ,w2= -0.13041039743723934 w3= 0.13303179950998983  ,w4= 36.81782972628557 w5= 0.12061292478289709  ,w0= 9.522488683320587 loss:  25.52292328875447  epoch: 59 \n",
      "\n",
      "Estimated weight: w1= 11.814869339343112  ,w2= -0.13040983490191305 w3= 0.13303134218968377  ,w4= 36.817832597009144 w5= 0.12061602949465432  ,w0= 9.522489787653878 loss:  25.52292328840956  epoch: 60 \n",
      "\n",
      "Estimated weight: w1= 11.814871092245195  ,w2= -0.1304093866944537 w3= 0.13303096758280958  ,w4= 36.817834845299274 w5= 0.12061852738296172  ,w0= 9.52249064820972 loss:  25.522923288190892  epoch: 61 \n",
      "\n",
      "Estimated weight: w1= 11.814872506556512  ,w2= -0.13040902976171054 w3= 0.13303066068662922  ,w4= 36.81783660628864 w5= 0.12062053681498716  ,w0= 9.522491318330493 loss:  25.522923288052084  epoch: 62 \n",
      "\n",
      "Estimated weight: w1= 11.814873647971522  ,w2= -0.13040874566088068 w3= 0.13303040922675152  ,w4= 36.81783798573421 w5= 0.12062215313345144  ,w0= 9.522491839766587 loss:  25.522923287963938  epoch: 63 \n",
      "\n",
      "Estimated weight: w1= 11.814874569368133  ,w2= -0.13040851964564198 w3= 0.1330302031599501  ,w4= 36.817839066411345 w5= 0.12062345311851548  ,w0= 9.522492245181674 loss:  25.522923287907954  epoch: 64 \n",
      "\n",
      "Estimated weight: w1= 11.814875313324793  ,w2= -0.1304083399316531 w3= 0.13303003426767476  ,w4= 36.81783991311426 w5= 0.12062449858927768  ,w0= 9.522492560118934 loss:  25.522923287872278  epoch: 65 \n",
      "\n",
      "Estimated weight: w1= 11.814875914139343  ,w2= -0.13040819710661347 w3= 0.13302989582372257  ,w4= 36.817840576567065 w5= 0.12062533930971575  ,w0= 9.522492804543827 loss:  25.522923287849636  epoch: 66 \n",
      "\n",
      "Estimated weight: w1= 11.814876399449156  ,w2= -0.13040808365673914 w3= 0.13302978232253898  ,w4= 36.81784109648299 w5= 0.12062601533259673  ,w0= 9.522492994054224 loss:  25.522923287835148  epoch: 67 \n",
      "\n",
      "Estimated weight: w1= 11.814876791531994  ,w2= -0.13040799358692093 w3= 0.13302968925708336  ,w4= 36.81784150395765 w5= 0.12062655888944794  ,w0= 9.52249314082935 loss:  25.522923287825915  epoch: 68 \n",
      "\n",
      "Estimated weight: w1= 11.814877108351029  ,w2= -0.13040792211621605 w3= 0.13302961293720958  ,w4= 36.817841823341425 w5= 0.12062699591404699  ,w0= 9.52249325437368 loss:  25.52292328782003  epoch: 69 \n",
      "\n",
      "Estimated weight: w1= 11.814877364394778  ,w2= -0.13040786543387778 w3= 0.13302955034116218  ,w4= 36.81784207370446 w5= 0.12062734727015169  ,w0= 9.522493342099873 loss:  25.52292328781633  epoch: 70 \n",
      "\n",
      "Estimated weight: w1= 11.814877571352486  ,w2= -0.13040782050400004 w3= 0.13302949899414118  ,w4= 36.81784226998317 w5= 0.12062762974062999  ,w0= 9.522493409785445 loss:  25.522923287813896  epoch: 71 \n",
      "\n",
      "Estimated weight: w1= 11.81487773865745  ,w2= -0.13040778490917762 w3= 0.13302945686899043  ,w4= 36.81784242387737 w5= 0.12062785682416892  ,w0= 9.522493461930372 loss:  25.522923287812393  epoch: 72 \n",
      "\n",
      "Estimated weight: w1= 11.814877873924292  ,w2= -0.13040775672545915 w3= 0.13302942230497214  ,w4= 36.81784254455258 w5= 0.12062803937685135  ,w0= 9.52249350203701 loss:  25.522923287811395  epoch: 73 \n",
      "\n",
      "Estimated weight: w1= 11.814877983301011  ,w2= -0.13040773442238263 w3= 0.13302939394132432  ,w4= 36.81784263918965 w5= 0.12062818612870002  ,w0= 9.522493532829124 loss:  25.52292328781075  epoch: 74 \n",
      "\n",
      "Estimated weight: w1= 11.814878071752553  ,w2= -0.13040771678310514 w3= 0.13302937066290377  ,w4= 36.81784271341506 w5= 0.12062830409947652  ,w0= 9.52249355642319 loss:  25.522923287810354  epoch: 75 \n",
      "\n",
      "Estimated weight: w1= 11.814878143289276  ,w2= -0.13040770284062012 w3= 0.1330293515557107  ,w4= 36.817842771637835 w5= 0.12062839893332421  ,w0= 9.522493574462304 loss:  25.522923287810094  epoch: 76 \n",
      "\n",
      "Estimated weight: w1= 11.814878201151105  ,w2= -0.1304076918268481 w3= 0.13302933587049312  ,w4= 36.817842817313306 w5= 0.1206284751680516  ,w0= 9.522493588220826 loss:  25.522923287809956  epoch: 77 \n",
      "\n",
      "Estimated weight: w1= 11.814878247956003  ,w2= -0.13040768313202353 w3= 0.1330293229929577  ,w4= 36.817842853149685 w5= 0.12062853645178906  ,w0= 9.522493598686083 loss:  25.52292328780979  epoch: 78 \n",
      "\n",
      "Estimated weight: w1= 11.814878285819717  ,w2= -0.13040767627231056 w3= 0.1330293124193855  ,w4= 36.817842881269804 w5= 0.12062858571727954  ,w0= 9.522493606622158 loss:  25.522923287809704  epoch: 79 \n",
      "\n",
      "Estimated weight: w1= 11.814878316452381  ,w2= -0.13040767086399446 w3= 0.13302930373666724  ,w4= 36.81784290333783 w5= 0.12062862532207029  ,w0= 9.522493612619636 loss:  25.522923287809704  epoch: 80 \n",
      "\n",
      "Estimated weight: w1= 11.81487834123648  ,w2= -0.13040766660292266 w3= 0.13302929660595614  ,w4= 36.81784292065847 w5= 0.12062865716126352  ,w0= 9.522493617134392 loss:  25.52292328780967  epoch: 81 \n",
      "\n",
      "Estimated weight: w1= 11.814878361289761  ,w2= -0.1304076632481361 w3= 0.1330292907492786  ,w4= 36.81784293425477 w5= 0.12062868275818847  ,w0= 9.522493620517805 loss:  25.522923287809675  epoch: 82 \n",
      "\n",
      "Estimated weight: w1= 11.81487837751605  ,w2= -0.13040766060884282 w3= 0.13302928593856714  ,w4= 36.817842944928955 w5= 0.12062870333731078  ,w0= 9.522493623040281 loss:  25.522923287809657  epoch: 83 \n",
      "\n",
      "Estimated weight: w1= 11.81487839064627  ,w2= -0.130407658534057 w3= 0.13302928198667568  ,w4= 36.81784295331019 w5= 0.1206287198828544  ,w0= 9.52249362490955 loss:  25.522923287809668  epoch: 84 \n",
      "\n",
      "Estimated weight: w1= 11.814878401271574  ,w2= -0.13040765690436112 w3= 0.13302927874001733  ,w4= 36.817842959891955 w5= 0.12062873318593181  ,w0= 9.522493626284886 loss:  25.522923287809665  epoch: 85 \n",
      "\n",
      "Estimated weight: w1= 11.814878409870127  ,w2= -0.13040765562536047 w3= 0.13302927607253043  ,w4= 36.81784296506134 w5= 0.12062874388243337  ,w0= 9.522493627288153 loss:  25.52292328780965  epoch: 86 \n",
      "\n",
      "Estimated weight: w1= 11.814878416828726  ,w2= -0.1304076546224842 w3= 0.1330292738807335  ,w4= 36.81784296912203 w5= 0.12062875248348506  ,w0= 9.522493628012372 loss:  25.522923287809622  epoch: 87 \n",
      "\n",
      "Estimated weight: w1= 11.814878422460287  ,w2= -0.13040765383685793 w3= 0.1330292720796703  ,w4= 36.81784297231232 w5= 0.12062875939993216  ,w0= 9.522493628528364 loss:  25.522923287809668  epoch: 88 \n",
      "\n",
      "Estimated weight: w1= 11.814878427017975  ,w2= -0.13040765322202919 w3= 0.13302927059958594  ,w4= 36.817842974819165 w5= 0.12062876496201856  ,w0= 9.522493628889888 loss:  25.522923287809636  epoch: 89 \n",
      "\n",
      "Estimated weight: w1= 11.814878430706626  ,w2= -0.13040765274137053 w3= 0.13302926938320034  ,w4= 36.81784297678931 w5= 0.12062876943520469  ,w0= 9.522493629137621 loss:  25.522923287809654  epoch: 90 \n",
      "\n",
      "Estimated weight: w1= 11.814878433691982  ,w2= -0.1304076523660206 w3= 0.13302926838347293  ,w4= 36.817842978337914 w5= 0.1206287730328815  ,w0= 9.522493629302222 loss:  25.522923287809647  epoch: 91 \n",
      "\n",
      "Estimated weight: w1= 11.814878436108158  ,w2= -0.13040765207325375 w3= 0.1330292675617678  ,w4= 36.8178429795554 w5= 0.12062877592658834  ,w0= 9.5224936294067 loss:  25.522923287809654  epoch: 92 \n",
      "\n",
      "Estimated weight: w1= 11.814878438063685  ,w2= -0.13040765184518832 w3= 0.13302926688634958  ,w4= 36.817842980512744 w5= 0.12062877825422591  ,w0= 9.522493629468244 loss:  25.522923287809682  epoch: 93 \n",
      "\n",
      "Estimated weight: w1= 11.814878439646392  ,w2= -0.1304076516677651 w3= 0.1330292663311481  ,w4= 36.81784298126567 w5= 0.12062878012665691  ,w0= 9.522493629499612 loss:  25.52292328780967  epoch: 94 \n",
      "\n",
      "Estimated weight: w1= 11.814878440927359  ,w2= -0.1304076515299388 w3= 0.13302926587474548  ,w4= 36.81784298185794 w5= 0.12062878163301088  ,w0= 9.52249362951022 loss:  25.522923287809647  epoch: 95 \n",
      "\n",
      "Estimated weight: w1= 11.814878441964108  ,w2= -0.13040765142303928 w3= 0.13302926549954497  ,w4= 36.817842982323945 w5= 0.12062878284494796  ,w0= 9.522493629506956 loss:  25.522923287809622  epoch: 96 \n",
      "\n",
      "Estimated weight: w1= 11.814878442803197  ,w2= -0.13040765134026655 w3= 0.13302926519108724  ,w4= 36.81784298269067 w5= 0.12062878382008592  ,w0= 9.522493629494807 loss:  25.52292328780962  epoch: 97 \n",
      "\n",
      "Estimated weight: w1= 11.814878443482305  ,w2= -0.13040765127629247 w3= 0.1330292649374906  ,w4= 36.817842982979336 w5= 0.12062878460475367  ,w0= 9.522493629477346 loss:  25.522923287809608  epoch: 98 \n",
      "\n",
      "Estimated weight: w1= 11.81487844403193  ,w2= -0.13040765122694598 w3= 0.13302926472899101  ,w4= 36.81784298320661 w5= 0.1206287852362057  ,w0= 9.522493629457088 loss:  25.522923287809675  epoch: 99 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.1 #learning rate\n",
    "max_epoch = 100 #number of iterations\n",
    "arrw, traininglossarr = training_model(X_train, y_train, alpha, max_epoch) \n",
    "#array that stores the estimated weights and training loss history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786038c3",
   "metadata": {},
   "source": [
    "## Display the estimated weights (after model training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8d2f846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated weights w1=11.81487844403193, w2=-0.13040765122694598, w3=0.13302926472899101, w4=36.81784298320661, w5=0.1206287852362057, w0=9.522493629457088\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimated weights w1={}, w2={}, w3={}, w4={}, w5={}, w0={}\".format(arrw[0],arrw[1],arrw[2],arrw[3],arrw[4],arrw[5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a57d68",
   "metadata": {},
   "source": [
    "# Prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3a99881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(w,X):\n",
    "    x1 = X['f1'].values\n",
    "    x2 = X['f2'].values\n",
    "    x3 = X['f3'].values\n",
    "    x4 = X['f4'].values\n",
    "    x5 = X['f5'].values\n",
    "    w1=w[0] #assign estimated weights\n",
    "    w2=w[1] \n",
    "    w3=w[2] \n",
    "    w4=w[3] \n",
    "    w5=w[4]\n",
    "    w0=w[5]\n",
    "    n= len(X)\n",
    "    y_predicted = np.array(n)\n",
    "    for i in range(n):\n",
    "        y_predicted = w1*x1+w2*x2+w3*x3+w4*x4+w5*x5+w0 #predicting values\n",
    "    \n",
    "    return y_predicted\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aafaccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = np.array(prediction(arrw,X_test))\n",
    "#storing y_predicted into yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4faecb5",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d85f48fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossfn(y,yhat):#using mean squared error formula\n",
    "    n = len(y)\n",
    "    y_actual = y.values\n",
    "    temp_loss_val=0\n",
    "    for i in range(n):\n",
    "        temp_loss_val+= (y_actual[i]-yhat[i])**2\n",
    "    \n",
    "    return (1/n)*temp_loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79897bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_value = lossfn(y_test,yhat)\n",
    "#store loss value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71d842b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epocharr = [1]*max_epoch #making array to plot the graph in x-axis\n",
    "for i in range(max_epoch):\n",
    "    epocharr[i] =i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6d9856",
   "metadata": {},
   "source": [
    "## Display the training loss against epoch graph (after model training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7fa2ea8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotiing graph using array\n",
    "x = epocharr\n",
    "y = traininglossarr\n",
    "\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('training loss')\n",
    "plt.plot(x, y,)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85f91a8",
   "metadata": {},
   "source": [
    "# R^2 function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85a47a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squared(y_test,y_hat):#r^2 formula\n",
    "    n = len(y_hat)\n",
    "    y_test_mean = np.mean(y_test)\n",
    "    \n",
    "    RSS = sum((y_test-yhat)**2)\n",
    "    TSS = sum((y_test-y_test_mean)**2)\n",
    "    \n",
    "    return (1 - (RSS/TSS))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4adace",
   "metadata": {},
   "source": [
    "## Evaluation and Display both R-squared & mean squared error measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ce74648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 value:  0.9817879703745107  Mean Squared Error(MSE):  22.912724210198718\n"
     ]
    }
   ],
   "source": [
    "r_squared_val = r_squared(y_test,yhat)\n",
    "print(\"R^2 value: \",r_squared_val,\" Mean Squared Error(MSE): \",loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fb11bc",
   "metadata": {},
   "source": [
    "### With a high training loss(>20), it is assumed that the estimated weights and prediction will be wrong. But suprisingly it predicted values quite close or far with range of (0.01 to 10). When compared to using skcit GD to sort, skcit GD has low training loss and more accurate prediction\n",
    "\n",
    "### since R^2 is close to 1, it is a good fit, MSE is above 20 while a perfect fit is 0.0 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
